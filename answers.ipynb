{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Movies\n",
    "This file is prepared to load some data about movies (80Mb CSV). It is a subset of 5 years (2016-2020) of the whole file: 500Mb.\n",
    "Lines: 170,695\n",
    "Columns: 29\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load the data\n",
    "Run the cell below once to load all movies data in a Pandas Dataframe. Consider a Dataframe as a Table on Steroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Load the movies data into a DataFrame\n",
    "movies_url = \"https://github.com/himmelreich-it/jupyter-teaser-workshop/raw/refs/heads/main/recent_movies.zip\"\n",
    "df = pd.read_csv(movies_url, compression='zip')\n",
    "\n",
    "# movies_url = \"all_movies.csv\"\n",
    "# df = pd.read_csv(movies_url)\n",
    "\n",
    "print(f\"{len(df):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Number of movies per year\n",
    "Aggregate the number of movies per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10 directors by number of movies\n",
    "# First, let's check how many movies have director information\n",
    "movies_with_year = df[df['year'].notna()]\n",
    "print(f\"Total movies in dataset: {len(df)}\")\n",
    "print(f\"Movies with year information: {len(movies_with_year)}\")\n",
    "print(f\"Movies without year information: {len(df) - len(movies_with_year)}\")\n",
    "\n",
    "# Count movies per director\n",
    "year_counts = movies_with_year['year'].value_counts()\n",
    "\n",
    "# Get top 10 directors\n",
    "year_counts = year_counts.reset_index()\n",
    "year_counts.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Average IMDB rating per director\n",
    "\n",
    "- Extra: Add Standard Deviation and Movie Count\n",
    "- Extra 2: Only directors with more than 5 movies are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_movie_count = 5\n",
    "\n",
    "# Average IMDB rating per director\n",
    "# Filter movies with both director and IMDB rating information\n",
    "movies_with_director = df[(df['director'].notna()) & (df['imdb_rating'].notna()) & (df['imdb_rating'] > 0)]\n",
    "\n",
    "# Group by director and calculate statistics\n",
    "director_stats = movies_with_director.groupby('director').agg({\n",
    "    'imdb_rating': ['mean', 'std', 'count']\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "director_stats.columns = ['avg_rating', 'rating_std', 'movie_count']\n",
    "\n",
    "# Filter directors with at least 5 movies for statistical relevance\n",
    "director_stats = director_stats[director_stats['movie_count'] >= min_movie_count]\n",
    "\n",
    "# Sort by average rating (descending) and reset index\n",
    "director_table = director_stats.sort_values('avg_rating', ascending=False).reset_index()\n",
    "\n",
    "# Display top 20 directors\n",
    "director_table.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Highest rated movies (20) below 100,000 USD\n",
    "Lets exclude short movies, defined as <80min and make sure we only include movies with a large voting base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to display\n",
    "display_columns = ['title', 'release_date','budget', 'imdb_rating', 'imdb_votes']\n",
    "\n",
    "# Filter movies under $100k\n",
    "low_budget = df[(df['budget'] < 100000) & (df['budget'] > 1000) & (df['runtime'] > 80) & (df['imdb_votes'] > 1000)]\n",
    "\n",
    "# Find highest by combined rating\n",
    "best_rated = low_budget.dropna(subset=['imdb_rating']).nlargest(20, 'imdb_rating').reset_index()\n",
    "\n",
    "best_rated_short = best_rated[display_columns]\n",
    "best_rated_short.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Do longer movies cost more\n",
    "\n",
    "Is there a correlation between the length of a movie and the cost associated with.\n",
    "- Do we need to exclude outliers in budget?\n",
    "- Do we only want to focus on \"normal\" movie length, 80-150min, or simply cater for outliers?\n",
    "- Do we want to show some graphs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rt_vs_budget = df[(df['runtime'] > 80) & (df['runtime'] < 300) & (df['budget'] > 500)].dropna(subset=['runtime', 'budget'])\n",
    "\n",
    "print(f\"Total movies with both Running Time and Budget: {len(rt_vs_budget)} ({(len(rt_vs_budget)/len(df))*100:.2f}%)\")\n",
    "print(f\"Running Time range: {rt_vs_budget['runtime'].min():.0f} - {rt_vs_budget['runtime'].max():.0f} minutes\")\n",
    "print(f\"Budgetrange: {rt_vs_budget['budget'].min():.1f} - {rt_vs_budget['budget'].max():.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "correlation, p_value = stats.pearsonr(rt_vs_budget['runtime'], rt_vs_budget['budget'])\n",
    "\n",
    "print(f\"\\nPearson Correlation Coefficient: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Relationship strength: {'Strong' if abs(correlation) > 0.7 else 'Moderate' if abs(correlation) > 0.3 else 'Weak'}\")\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0,0].scatter(rt_vs_budget['runtime'], rt_vs_budget['budget'], alpha=0.6)\n",
    "axes[0,0].set_xlabel('Running Time (minutes)')\n",
    "axes[0,0].set_ylabel('Budget')\n",
    "axes[0,0].set_title('Budget vs Running Time')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(rt_vs_budget['runtime'], rt_vs_budget['budget'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0,0].plot(rt_vs_budget['runtime'], p(rt_vs_budget['runtime']), \"r--\", alpha=0.8)\n",
    "\n",
    "# Hexbin plot for density\n",
    "axes[0,1].hexbin(rt_vs_budget['runtime'], rt_vs_budget['budget'], gridsize=30, cmap='Blues')\n",
    "axes[0,1].set_xlabel('Running Time (minutes)')\n",
    "axes[0,1].set_ylabel('Budget')\n",
    "axes[0,1].set_title('Density Plot: Budget vs Running Time')\n",
    "\n",
    "# Box plot by running time categories\n",
    "# Create running time categories\n",
    "clean_data_copy = rt_vs_budget.copy()\n",
    "clean_data_copy['Runtime_Category'] = pd.cut(clean_data_copy['runtime'], \n",
    "                                           bins=[0, 90, 120, 150, 300], \n",
    "                                           labels=['Short (<90min)', 'Medium (90-120min)', \n",
    "                                                  'Long (120-150min)', 'Very Long (>150min)'])\n",
    "\n",
    "clean_data_copy.boxplot(column='budget', by='Runtime_Category', ax=axes[1,0])\n",
    "axes[1,0].set_title('Budget Distribution by Runtime Category')\n",
    "axes[1,0].set_xlabel('Runtime Category')\n",
    "\n",
    "# Distribution of running times\n",
    "axes[1,1].hist(rt_vs_budget['runtime'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_xlabel('Running Time (minutes)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('Distribution of Running Times')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Do longer movies get a better rating\n",
    "\n",
    "Is there a correlation between IMDB Rating and the Length of the Movie...\n",
    "- Do we need to exclude outliers in rating?\n",
    "- Do we only want to focus on \"normal\" movie length, 80-150min, or simply cater for outliers?\n",
    "- Do we want to show some graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Clean the data - remove rows where either Running Time or IMDB Rating is missing\n",
    "clean_data = df[(df['runtime'] > 10) & (df['runtime'] < 300) & (df['imdb_rating'] > 0) & (df['imdb_rating'] < 10)].dropna(subset=['runtime', 'imdb_rating'])\n",
    "\n",
    "print(f\"Total movies with both Running Time and IMDB Rating: {len(clean_data)} ({(len(clean_data)/len(df))*100:.2f}%)\")\n",
    "print(f\"Running Time range: {clean_data['runtime'].min():.0f} - {clean_data['runtime'].max():.0f} minutes\")\n",
    "print(f\"IMDB Rating range: {clean_data['imdb_rating'].min():.1f} - {clean_data['imdb_rating'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient\n",
    "correlation, p_value = stats.pearsonr(clean_data['runtime'], clean_data['imdb_rating'])\n",
    "\n",
    "print(f\"\\nPearson Correlation Coefficient: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Relationship strength: {'Strong' if abs(correlation) > 0.7 else 'Moderate' if abs(correlation) > 0.3 else 'Weak'}\")\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0,0].scatter(clean_data['runtime'], clean_data['imdb_rating'], alpha=0.6)\n",
    "axes[0,0].set_xlabel('Running Time (minutes)')\n",
    "axes[0,0].set_ylabel('IMDB Rating')\n",
    "axes[0,0].set_title('IMDB Rating vs Running Time')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(clean_data['runtime'], clean_data['imdb_rating'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0,0].plot(clean_data['runtime'], p(clean_data['runtime']), \"r--\", alpha=0.8)\n",
    "\n",
    "# Hexbin plot for density\n",
    "axes[0,1].hexbin(clean_data['runtime'], clean_data['imdb_rating'], gridsize=30, cmap='Blues')\n",
    "axes[0,1].set_xlabel('Running Time (minutes)')\n",
    "axes[0,1].set_ylabel('IMDB Rating')\n",
    "axes[0,1].set_title('Density Plot: IMDB Rating vs Running Time')\n",
    "\n",
    "# Box plot by running time categories\n",
    "# Create running time categories\n",
    "clean_data_copy = clean_data.copy()\n",
    "clean_data_copy['Runtime_Category'] = pd.cut(clean_data_copy['runtime'], \n",
    "                                           bins=[0, 90, 120, 150, 300], \n",
    "                                           labels=['Short (<90min)', 'Medium (90-120min)', \n",
    "                                                  'Long (120-150min)', 'Very Long (>150min)'])\n",
    "\n",
    "clean_data_copy.boxplot(column='imdb_rating', by='Runtime_Category', ax=axes[1,0])\n",
    "axes[1,0].set_title('IMDB Rating Distribution by Runtime Category')\n",
    "axes[1,0].set_xlabel('Runtime Category')\n",
    "\n",
    "# Distribution of running times\n",
    "axes[1,1].hist(clean_data['runtime'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_xlabel('Running Time (minutes)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('Distribution of Running Times')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
